#Модели:
# google/gemma-3-1b-pt 
# google/gemma-3-4b-pt
# meta-llama/Llama-3.1-8B-Instruct

#Параметры для загрузки модели
model:
  name: "Qwen/Qwen3-0.6B"
  model_name_log: "qwen_3__0_6b"
  full_path_for_model : "../app_qna/modelcachedir/models--Qwen--Qwen3-0.6B/snapshots/c1899de289a04d12100db370d81485cdf75e47ca"
  max_length: 512
  max_new_tokens: 32
    
  tokenizer:
    padding_size: "left"
    answer_pattern: "### Answer:\n"

#Параметры для конфигурации LoRA
lora:
  r: 32
  lora_alpha: 64
  lora_dropout: 0.05
  target_modules: ["q_proj", "o_proj"] #"v_proj", "k_proj"

#Параметры для инференса
inference:
  temp: 0.4

#Параметры для обучения
train:
  model_save_dir: "./saved_models"
  epochs: 1
  train_batch: 1
  val_batch: 1
  test_batch: 1
  grad_accum: 5
  eval_step: 500
  save_step: 500
  torch_empty_cache_steps: 8
  log_step: 50
  lr: 0.00002
  weight_decay: 0.01

#Директория для логов
logs:
  dir: "./logs_v2"
  finemae : "run_log_tining_v1.log"

data:
  path: "./data"
  cache_file_name_train : "./data/cache_squad_train.cache"
  cache_file_name_val : "./data/cache_squad_val.cache"


#Для оценки обученной модели
tuning_model:
  full_path2adapters: "./saved_models/train__13-08-2025_11-35-28__qwen_3__0_6b"
  checkpoint: "checkpoint-200"